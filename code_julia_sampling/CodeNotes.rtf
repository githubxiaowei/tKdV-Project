{\rtf1\ansi\ansicpg1252\cocoartf1561\cocoasubrtf610
{\fonttbl\f0\froman\fcharset0 TimesNewRomanPSMT;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\margl1440\margr1440\vieww11000\viewh9920\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs28 \cf0 \ul \ulc0 \
Instructions\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 \ulnone \'95 The routine uniform_sample(nmodes, nsweeps) samples from the uniform distribution and produces the output file rand.jld, which contains a list of H2 and H3 values (as well as some parameters). Here nmodes = Lambda is specified but lamfac = N is not specified. The number of samples per sweep is 1e5.\
\
\'95 The routine transfun(\'93rand-16-20\'94, lamfac) computes the transfer function and produces the output file thvars.jld, which contains the upstream and downstream theta values and the skewness upstream and downstream (as well as some parameters).\ul \
\
\ulnone \'95 The routine output_text(\'93thvars-16-8-20.jld\'94) converts the julia file to a text file for DataTank to read.\
\
\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 \ul Plan\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 \ulnone To address Ref1 question about convergence of the transfer function for Lambda large, I plan to run a series of samples with Lambda = 16, 32, and maybe 64. I plan to use 500 and 1000 sweeps to get a visual on the convergence with respect to the number of samples. The value of N does not need to be set in the sampling stage, only later on the transfer function stage. I will primarily use N = Lambda/2, but can also experiment with N = 8 fixed as a straw man.\ul \
\ulnone \
\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 \ul Timing\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 \ulnone \
Original version of code with bad FFT strategy\
Lambda	nsweeps	sampling	transfer	\
16		10		0.27 mins	0.32 mins\
16		100		2.8 mins	3.3 mins\
24		100		*14 mins\
32		100		2.9 mins\
64		100		*16 mins\
\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 *Interesting: Lambda = 24 takes much longer than Lambda = 32, which means that the fft routines I am using are very suboptimal. Likely, making a FFTW plan, or else simply computing the transform directly, would be faster for the moderate values of Lambda I am using. Online search suggests the break-even for FFT over direct is about 64.\
*I don\'92t know why Lambda = 64 takes so much longer than 32.\
\
Original version of code with bad FFT strategy\
Lambda	nsweeps	sampling	transfer	\
16		500		14 mins\
16		1000		28 mins\
32		500		15 mins\
32		1000		34 mins\
\
Conclusions:\
The cpu time of computing the transfer function is very close to the cpu time of sampling and this relationship seems to scale with nsweeps getting bigger.\
\
Comparing the sampling with the original bad FFT versus direct\
Lambda	nsweeps	bad FFT	direct H3\
16		10		0.27 mins	0.046 mins\
The difference is about a factor of six!!!\
\
\
\
\
\
\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 \ul Recoding FFT\ulnone \
- The only code that uses the FFT is ham3.\
\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 - I should use FFTW \'91plan\'92, since I am doing transforms of exactly the same size over and over again.\
References:\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
{\field{\*\fldinst{HYPERLINK "http://www.fftw.org/fftw2_doc/fftw_2.html"}}{\fldrslt \cf0 http://www.fftw.org/fftw2_doc/fftw_2.html}}\
{\field{\*\fldinst{HYPERLINK "https://www.reddit.com/r/Julia/comments/5wel0j/fft_speed_vs_matlab/"}}{\fldrslt https://www.reddit.com/r/Julia/comments/5wel0j/fft_speed_vs_matlab/}}\
{\field{\*\fldinst{HYPERLINK "https://www.juliabloggers.com/tag/fftw/"}}{\fldrslt https://www.juliabloggers.com/tag/fftw/}}\
{\field{\*\fldinst{HYPERLINK "https://biojulia.net/post/hardware/"}}{\fldrslt https://biojulia.net/post/hardware/}}\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 \
\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 \ul To do\ulnone \
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 \
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 - I need to test the accuracy of ham3 versus ham3direct.\
\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 - I should do a breakeven test of H3 with fft versus direct.\
\
- In transfer function, I need to see how many iterations the root solver is taking and think about improving that.\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 \
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 \ul Notes\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 \ulnone \
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 FFT tests\
- I was worried about the fact that I am calling irfft with vectors of length 33 and 64, since 33 is not a power of 2. Maybe this is okay since it is the real fft, but I decided to test it. I tested several variations, like (32,63), (32,62), and (33, 65), but the fastest one was the one I originally had coded (33, 64). Thus, I believe I was already using the real FFT with vectors of the correct length.\
- For using irfft(uhat, uu), the length of uu must be either npoints = 2*nmodes or 2*nmodes+1. I have found that npoints = 2*nmodes is certainly faster and may be slightly more accurate.\
\
- In the long run, the better strategy is to sample from a better prior, or to do some basic AR because transfun has to deal with enormously long lists and the vast majority of those are wasted in the mean because their weight is nearly zero.\
\
- Man it would be cool to figure out how to run this sampling algorithm on GPUs. It seems like it would be appropriate since it involves doing the same exact simple arithmetic instructions for multiple data. The only little thing I am worried about is if the GPU is efficient at handling FFT, but I\'92m sure there is a way to do this. Also, I really do need to do some preliminary AR to pare down the data files of stored H2 and H3 values.\
\
\
\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 \ul Little things\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 \ulnone - I define the data type RandList with ravar, H2, and H3, but I do not actually use rvar in any of the routines, so maybe I have been silly with my definition.}