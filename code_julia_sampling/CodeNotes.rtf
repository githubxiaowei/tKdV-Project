{\rtf1\ansi\ansicpg1252\cocoartf1561\cocoasubrtf610
{\fonttbl\f0\froman\fcharset0 TimesNewRomanPSMT;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\margl1440\margr1440\vieww11000\viewh9920\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs28 \cf0 \ul \ulc0 \

\b\fs40 \ulnone To do
\b0\fs28 \
\
- I need to test the accuracy of ham3 versus ham3direct.\
\
- I should do a breakeven test of H3 with fft versus direct.\
\
- In transfer function, I need to see how many iterations the root solver is taking and think about improving that.\ul \
\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 \ulnone To address Ref1 question about convergence of the transfer function for Lambda large, I plan to run a series of samples with Lambda = 16, 32, and maybe 64. I plan to use 500 and 1000 sweeps to get a visual on the convergence with respect to the number of samples. The value of N does not need to be set in the sampling stage, only later on the transfer function stage. I will primarily use N = Lambda/2, but can also experiment with N = 8 fixed as a straw man.\ul \
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 \ulc0 \
Little things\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 \ulnone - I define the data type RandList with ravar, H2, and H3, but I do not actually use rvar in any of the routines, so maybe I have been silly with my definition.\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 \ul \
\

\b\fs40 \ulnone Instructions for running code
\b0\fs28 \ul \
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 \ulnone \'95 The routine uniform_sample(nmodes, nsweeps) samples from the uniform distribution and produces the output file rand.jld, which contains a list of H2 and H3 values (as well as some parameters). Here nmodes = Lambda is specified but lamfac = N is not specified. The number of samples per sweep is 1e5.\
\
\'95 The routine transfun(\'93rand-16-20\'94, lamfac) computes the transfer function and produces the output file thvars.jld, which contains the upstream and downstream theta values and the skewness upstream and downstream (as well as some parameters).\ul \
\
\ulnone \'95 The routine output_text(\'93thvars-16-8-20.jld\'94) converts the julia file to a text file for DataTank to read.\
\
\
\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\b\fs40 \cf0 Timing
\b0\fs28 \ul \ulc0 \
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 \ulnone \
Original version of code using FFT (no FFT plan)\
Lambda	nsweeps	sampling	transfer	\
16		100		2.8 mins	3.3 mins\
24		100		*14 mins\
32		100		2.9 mins\
64		100		*16 mins\
\
*Interesting: Lambda = 24 takes much longer than Lambda = 32, which means that the fft routines I am using are very suboptimal. Likely, making a FFTW plan, or else simply computing the transform directly, would be faster for the moderate values of Lambda I am using. Online search suggests the break-even for FFT over direct is about 64.\
*I don\'92t know why Lambda = 64 takes so much longer than 32.\
\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 Original version of code using FFT (no FFT plan)\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 Lambda	nsweeps	sampling	transfer	\
16		500		14 mins\
16		1000		28 mins\
32		500		15 mins\
32		1000		34 mins\
\
Conclusions:\
The cpu time of computing the transfer function is very close to the cpu time of sampling and this relationship seems to scale with nsweeps getting bigger.\
\
\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 \ul H3 with FFT vs direct\ulnone \
Comparing the sampling with the original FFT with no plan versus direct computation of H3\
Lambda	nsweeps	bad FFT	direct H3\
16		10		0.27 mins	0.046 mins\
The direct computation of H3 is faster by about a factor of six!!!\
\
\
\
\

\b\fs40 FFT Notes
\b0\fs28 \ul \
\
Real FFT nuances\ulnone \
- To use real FFT between physical uu and spectral uhat, the relationship len(uhat) = div(len(uu), 2) + 1 must be satisfied. Note that in using irfft, the length of uu cannot be inferred from uhat because it can be either 2*len(uhat)-1 or 2*len(uhat)-2. Reference: {\field{\*\fldinst{HYPERLINK "https://juliamath.github.io/AbstractFFTs.jl/stable/api/"}}{\fldrslt https://juliamath.github.io/AbstractFFTs.jl/stable/api/}}\
\
- In my application, we take the irfft of vector [0; uhat] where uhat has length nmodes. We have to do this to include the zero-mode which is set to zero. Thus, the length of uu npoints is either npoints = 2*nmodes or 2*nmodes+1. In my tests, npoints = 2*nmodes seems to be highly preferred. It is much faster (by a factor of at least two) and maybe slightly more accurate according to the benchmarks.\
\
- At some point, I was worried because the above implies that I am calling irfft with vectors of highly non-composite length. For example, if nmodes=16, then the vector [0; uhat] has length 17 and thus, after upsampling, I am calling irfft with vectors of length (33, 64). The 33 worried me. So I ran some tests where I slightly varied the lengths of the vectors by zeroing the last mode or not and by setting npoints to the two different values allowed. I ran tests calling irfft with vectors of length (32, 63), (32, 62), and (33, 65). The original implementation of (33, 64) was by far the fastest to execute by a factor of more than two. Thus, I believe I was already using the real FFT with vectors of the correct length.\
\
\ul Recoding FFT\ulnone \
- The only code that uses the fft routines is ham3; it uses irealfft only. The routine realfft is unused except in the benchmark of H3.\
\
- I should use FFTW \'91plan\'92, since I am doing transforms of exactly the same size over and over again.\
References:\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
{\field{\*\fldinst{HYPERLINK "http://www.fftw.org/fftw2_doc/fftw_2.html"}}{\fldrslt \cf0 http://www.fftw.org/fftw2_doc/fftw_2.html}}\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
{\field{\*\fldinst{HYPERLINK "https://www.reddit.com/r/Julia/comments/5wel0j/fft_speed_vs_matlab/"}}{\fldrslt \cf0 https://www.reddit.com/r/Julia/comments/5wel0j/fft_speed_vs_matlab/}}\
{\field{\*\fldinst{HYPERLINK "https://www.juliabloggers.com/tag/fftw/"}}{\fldrslt https://www.juliabloggers.com/tag/fftw/}}\
{\field{\*\fldinst{HYPERLINK "https://biojulia.net/post/hardware/"}}{\fldrslt https://biojulia.net/post/hardware/}}\
\
\
\
\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\b\fs40 \cf0 Long term\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\b0\fs28 \cf0 \
- In the long run, the better strategy is to sample from a better prior, or to do some basic AR because transfun has to deal with enormously long lists and the vast majority of those are wasted in the mean because their weight is nearly zero.\
\
- Man it would be cool to figure out how to run this sampling algorithm on GPUs. It seems like it would be appropriate since it involves doing the same exact simple arithmetic instructions for multiple data. The only little thing I am worried about is if the GPU is efficient at handling FFT, but I\'92m sure there is a way to do this. Also, I really do need to do some preliminary AR to pare down the data files of stored H2 and H3 values.\
}